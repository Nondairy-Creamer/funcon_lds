data_path: /home/mcreamer/Documents/data_sets/fun_con/
# some data sets are unreliable, remove them
bad_data_sets: []

# the calcium dynamics always look strange at the start of a recording, possibly due to the laser being turned on
# cut out the first ~15 seconds to let the system equilibrate
start_index: 25

# We want to take our data set of recordings and pick a subset of those recordings and neurons in order
# to maximize the number of recordings * the number of neurons that appear in those recordings
# this variable allows a neuron to only appear in this fraction of recordings to still be included
# (rather than enforcing it is in 100% of the recording subset)
frac_neuron_coverage: 0.0

# for a neuron to be included in the dataset, it must be in at least this fraction of the recordings
# this is not a principled threshold, (you could have 90 bad recordings and 10 good ones), but it's a quick heuristic
# to reduce dataset size
minimum_frac_measured: 0.3

num_data_sets: 10

param_props:
  update:
    dynamics_weights: True
    dynamics_input_weights: True
    dynamics_offset: False
    dynamics_cov: True
    emissions_weights: False
    emissions_input_weights: False
    emissions_offset: False
    emissions_cov: True

  shape:
    dynamics_input_weights: diag
    dynamics_cov: full
    emissions_cov: full

  mask:
    dynamics_input_weights: Null

device: cpu
dtype: float64

# gradient descent parameters
# choices are: gradient_descent and batch_sgd
dynamics_lags: 2
dynamics_input_lags: 4
fit_type: em
num_train_steps: 50
verbose: True

plot_figures: True
model_save_folder: trained_models



