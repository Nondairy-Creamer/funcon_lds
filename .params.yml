data_path: C:\Users\mcreamer\Documents\data_sets\funcon
# some data sets are unreliable, remove them
bad_data_sets: [0, 4, 6, 10, 11, 15, 17, 24, 35, 37, 45]

# the calcium dynamics always look strange at the start of a recording, possibly due to the laser being turned on
# cut out the first ~15 seconds to let the system equilibrate
index_start: 25

# We want to take our data set of recordings and pick a subset of those recordings and neurons in order
# to maximize the number of recordings * the number of neurons that appear in those recordings
# this variable allows a neuron to only appear in this fraction of recordings to still be included
# (rather than enforcing it is in 100% of the recording subset)
frac_neuron_coverage: 0.0

# for a neuron to be included in the dataset, it must be in at least this fraction of the recordings
# this is not a principled threshold, (you could have 90 bad recordings and 10 good ones), but it's a quick heuristic
# to reduce dataset size
minimum_frac_measured: 0.0

param_props:
  update:
    dynamics_offset: False
    emissions_weights: False
    emissions_input_weights: False
    emissions_offset: False

  shape:
    dynamics_input_weights: diag
    dynamics_cov: full
    emissions_cov: full

device: cpu
dtype: float64

# gradient descent parameters
# choices are: gradient_descent and batch_sgd
num_lags: 3
fit_type: em
num_grad_steps: 10
learning_rate: 0.001
verbose: True
random_seed: null

plot_figures: False
save_model: True
model_save_folder: trained_models



